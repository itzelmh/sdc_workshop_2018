{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a file with Pandas\n",
    "==\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a library widely used for statistics and analysis\n",
    "* Has functions which allow you to read a file directly into your script\n",
    "* Borrows many feature from R's data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Read a Comma Separate Values (CSV) data file with `pandas.read_csv`.\n",
    "    * Uses the same notation as you used for bash (\"./\" accesses the current folder, \"../\" searches up to the parent folder)\n",
    "    * Argument is the name of the file to be read.\n",
    "    * Assign result to a variable to store the data that was read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Files\n",
    "\n",
    "We're using the gapminder data that we created yesterday. Remember that these are stored in the shell_lessons directory in a `data` sub-directory, which is why the path to the file is `../shell_lessons/data/gapminder_data/gapminder_final.txt`. If you forget to include `../shell_lessons/`, or if you include it but your copy of the file is somewhere else, you will get a [runtime error]({{ site.github.url }}/05-error-messages/) that ends with a line like this:\n",
    "    ~~~\n",
    "    OSError: File b'gapminder_final.txt' does not exist\n",
    "    ~~~\n",
    "    \n",
    "** Don't forget to use the tab key for auto-completion **\n",
    "    * Auto-complete works in Jupyter notebooks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, import the pandas library\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_table in module pandas.io.parsers:\n",
      "\n",
      "read_table(filepath_or_buffer, sep='\\t', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal=b'.', lineterminator=None, quotechar='\"', quoting=0, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=False, error_bad_lines=True, warn_bad_lines=True, skipfooter=0, skip_footer=0, doublequote=True, delim_whitespace=False, as_recarray=False, compact_ints=False, use_unsigned=False, low_memory=True, buffer_lines=None, memory_map=False, float_precision=None)\n",
      "    Read general delimited file into DataFrame\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the `online docs for IO Tools\n",
      "    <http://pandas.pydata.org/pandas-docs/stable/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, pathlib.Path, py._path.local.LocalPath or any object with a read() method (such as a file handle or StringIO)\n",
      "        The string could be a URL. Valid URL schemes include http, ftp, s3, and\n",
      "        file. For file URLs, a host is expected. For instance, a local file could\n",
      "        be file ://localhost/path/to/table.csv\n",
      "    sep : str, default \\t (tab-stop)\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used automatically. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``\n",
      "    delimiter : str, default ``None``\n",
      "        Alternative argument name for sep.\n",
      "    delim_whitespace : boolean, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    \n",
      "        .. versionadded:: 0.18.1 support for the Python parser.\n",
      "    \n",
      "    header : int or list of ints, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the data.\n",
      "        Default behavior is as if set to 0 if no ``names`` passed, otherwise\n",
      "        ``None``. Explicitly pass ``header=0`` to be able to replace existing\n",
      "        names. The header can be a list of integers that specify row locations for\n",
      "        a multi-index on the columns e.g. [0,1,3]. Intervening rows that are not\n",
      "        specified will be skipped (e.g. 2 in this example is skipped). Note that\n",
      "        this parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so header=0 denotes the first line of data\n",
      "        rather than the first line of the file.\n",
      "    names : array-like, default None\n",
      "        List of column names to use. If file contains no header row, then you\n",
      "        should explicitly pass header=None. Duplicates in this list are not\n",
      "        allowed unless mangle_dupe_cols=True, which is the default.\n",
      "    index_col : int or sequence or False, default None\n",
      "        Column to use as the row labels of the DataFrame. If a sequence is given, a\n",
      "        MultiIndex is used. If you have a malformed file with delimiters at the end\n",
      "        of each line, you might consider index_col=False to force pandas to _not_\n",
      "        use the first column as the index (row names)\n",
      "    usecols : array-like or callable, default None\n",
      "        Return a subset of the columns. If array-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). For example, a valid array-like\n",
      "        `usecols` parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    as_recarray : boolean, default False\n",
      "        DEPRECATED: this argument will be removed in a future version. Please call\n",
      "        `pd.read_csv(...).to_records()` instead.\n",
      "    \n",
      "        Return a NumPy recarray instead of a DataFrame after parsing the data.\n",
      "        If set to True, this option takes precedence over the `squeeze` parameter.\n",
      "        In addition, as row indices are not available in such a format, the\n",
      "        `index_col` parameter will be ignored.\n",
      "    squeeze : boolean, default False\n",
      "        If the parsed data only contains one column then return a Series\n",
      "    prefix : str, default None\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    mangle_dupe_cols : boolean, default True\n",
      "        Duplicate columns will be specified as 'X.0'...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    dtype : Type name or dict of column -> type, default None\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "        Use `str` or `object` to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    engine : {'c', 'python'}, optional\n",
      "        Parser engine to use. The C engine is faster while the python engine is\n",
      "        currently more feature-complete.\n",
      "    converters : dict, default None\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels\n",
      "    true_values : list, default None\n",
      "        Values to consider as True\n",
      "    false_values : list, default None\n",
      "        Values to consider as False\n",
      "    skipinitialspace : boolean, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like or integer or callable, default None\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c')\n",
      "    skip_footer : int, default 0\n",
      "        DEPRECATED: use the `skipfooter` parameter instead, as they are identical\n",
      "    nrows : int, default None\n",
      "        Number of rows of file to read. Useful for reading pieces of large files\n",
      "    na_values : scalar, str, list-like, or dict, default None\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'nan'`.\n",
      "    keep_default_na : bool, default True\n",
      "        If na_values are specified and keep_default_na is False the default NaN\n",
      "        values are overridden, otherwise they're appended to.\n",
      "    na_filter : boolean, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file\n",
      "    verbose : boolean, default False\n",
      "        Indicate number of NA values placed in non-numeric columns\n",
      "    skip_blank_lines : boolean, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values\n",
      "    parse_dates : boolean or list of ints or names or list of lists or dict, default False\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of ints or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call result\n",
      "          'foo'\n",
      "    \n",
      "        If a column or index contains an unparseable date, the entire column or\n",
      "        index will be returned unaltered as an object data type. For non-standard\n",
      "        datetime parsing, use ``pd.to_datetime`` after ``pd.read_csv``\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : boolean, default False\n",
      "        If True and parse_dates is enabled, pandas will attempt to infer the format\n",
      "        of the datetime strings in the columns, and if it can be inferred, switch\n",
      "        to a faster method of parsing them. In some cases this can increase the\n",
      "        parsing speed by 5-10x.\n",
      "    keep_date_col : boolean, default False\n",
      "        If True and parse_dates specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, default None\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call date_parser in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by parse_dates into a single array\n",
      "        and pass that; and 3) call date_parser once for each row using one or more\n",
      "        strings (corresponding to the columns defined by parse_dates) as arguments.\n",
      "    dayfirst : boolean, default False\n",
      "        DD/MM format dates, international and European format\n",
      "    iterator : boolean, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    chunksize : int, default None\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer', then use gzip,\n",
      "        bz2, zip or xz if filepath_or_buffer is a string ending in '.gz', '.bz2',\n",
      "        '.zip', or 'xz', respectively, and no decompression otherwise. If using\n",
      "        'zip', the ZIP file must contain only one data file to be read in.\n",
      "        Set to None for no decompression.\n",
      "    \n",
      "        .. versionadded:: 0.18.1 support for 'zip' and 'xz' compression.\n",
      "    \n",
      "    thousands : str, default None\n",
      "        Thousands separator\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    float_precision : string, default None\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are `None` for the ordinary converter,\n",
      "        `high` for the high-precision converter, and `round_trip` for the\n",
      "        round-trip converter.\n",
      "    lineterminator : str (length 1), default None\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : boolean, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), default None\n",
      "        One-character string used to escape delimiter when quoting is QUOTE_NONE.\n",
      "    comment : str, default None\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if comment='#', parsing '#empty\\na,b,c\\n1,2,3'\n",
      "        with `header=0` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, default None\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_\n",
      "    dialect : str or csv.Dialect instance, default None\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    tupleize_cols : boolean, default False\n",
      "        Leave a list of tuples on columns as is (default is to convert to\n",
      "        a Multi Index on the columns)\n",
      "    error_bad_lines : boolean, default True\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
      "        returned.\n",
      "    warn_bad_lines : boolean, default True\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    low_memory : boolean, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser)\n",
      "    buffer_lines : int, default None\n",
      "        DEPRECATED: this argument will be removed in a future version because its\n",
      "        value is not respected by the parser\n",
      "    compact_ints : boolean, default False\n",
      "        DEPRECATED: this argument will be removed in a future version\n",
      "    \n",
      "        If compact_ints is True, then for any column that is of integer dtype,\n",
      "        the parser will attempt to cast it as the smallest integer dtype possible,\n",
      "        either signed or unsigned depending on the specification from the\n",
      "        `use_unsigned` parameter.\n",
      "    use_unsigned : boolean, default False\n",
      "        DEPRECATED: this argument will be removed in a future version\n",
      "    \n",
      "        If integer columns are being compacted (i.e. `compact_ints=True`), specify\n",
      "        whether the column should be compacted to the smallest signed or unsigned\n",
      "        integer dtype.\n",
      "    memory_map : boolean, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : DataFrame or TextParser\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pandas.read_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then read the csv\n",
    "df = pandas.read_table(\"../data/processed_data/gapminder_data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " print the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>continent</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1997</td>\n",
       "      <td>22227415.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>41.763</td>\n",
       "      <td>635.341351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2002</td>\n",
       "      <td>25268405.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>42.129</td>\n",
       "      <td>726.734055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2007</td>\n",
       "      <td>31889923.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>43.828</td>\n",
       "      <td>974.580338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1952</td>\n",
       "      <td>8425333.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>28.801</td>\n",
       "      <td>779.445314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1957</td>\n",
       "      <td>9240934.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>30.332</td>\n",
       "      <td>820.853030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1962</td>\n",
       "      <td>10267083.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>31.997</td>\n",
       "      <td>853.100710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1967</td>\n",
       "      <td>11537966.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>34.020</td>\n",
       "      <td>836.197138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1972</td>\n",
       "      <td>13079460.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>36.088</td>\n",
       "      <td>739.981106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1977</td>\n",
       "      <td>14880372.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>38.438</td>\n",
       "      <td>786.113360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1982</td>\n",
       "      <td>12881816.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>39.854</td>\n",
       "      <td>978.011439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1987</td>\n",
       "      <td>13867957.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>40.822</td>\n",
       "      <td>852.395945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1992</td>\n",
       "      <td>16317921.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>41.674</td>\n",
       "      <td>649.341395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1952</td>\n",
       "      <td>1282697.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>55.230</td>\n",
       "      <td>1601.056136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1957</td>\n",
       "      <td>1476505.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>59.280</td>\n",
       "      <td>1942.284244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1962</td>\n",
       "      <td>1728137.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>64.820</td>\n",
       "      <td>2312.888958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1967</td>\n",
       "      <td>1984060.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>66.220</td>\n",
       "      <td>2760.196931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1972</td>\n",
       "      <td>2263554.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>67.690</td>\n",
       "      <td>3313.422188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1977</td>\n",
       "      <td>2509048.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>68.930</td>\n",
       "      <td>3533.003910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1982</td>\n",
       "      <td>2780097.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>70.420</td>\n",
       "      <td>3630.880722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>3075321.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>72.000</td>\n",
       "      <td>3738.932735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1992</td>\n",
       "      <td>3326498.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>71.581</td>\n",
       "      <td>2497.437901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1997</td>\n",
       "      <td>3428038.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>72.950</td>\n",
       "      <td>3193.054604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2002</td>\n",
       "      <td>3508512.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>75.651</td>\n",
       "      <td>4604.211737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2007</td>\n",
       "      <td>3600523.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>76.423</td>\n",
       "      <td>5937.029526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>1962</td>\n",
       "      <td>11000948.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>48.303</td>\n",
       "      <td>2550.816880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>1967</td>\n",
       "      <td>12760499.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>51.407</td>\n",
       "      <td>3246.991771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>1972</td>\n",
       "      <td>14760787.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>54.518</td>\n",
       "      <td>4182.663766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>1977</td>\n",
       "      <td>17152804.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>58.014</td>\n",
       "      <td>4910.416756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>1982</td>\n",
       "      <td>20033753.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>61.368</td>\n",
       "      <td>5745.160213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>1952</td>\n",
       "      <td>9279525.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>43.077</td>\n",
       "      <td>2449.008185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>1982</td>\n",
       "      <td>9657618.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>49.113</td>\n",
       "      <td>1977.557010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>1987</td>\n",
       "      <td>11219340.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>52.922</td>\n",
       "      <td>1971.741538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>1992</td>\n",
       "      <td>13367997.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>55.599</td>\n",
       "      <td>1879.496673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>1997</td>\n",
       "      <td>15826497.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>58.020</td>\n",
       "      <td>2117.484526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>2002</td>\n",
       "      <td>18701257.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>60.308</td>\n",
       "      <td>2234.820827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>2007</td>\n",
       "      <td>22211743.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>62.698</td>\n",
       "      <td>2280.769906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1952</td>\n",
       "      <td>2672000.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>42.038</td>\n",
       "      <td>1147.388831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1957</td>\n",
       "      <td>3016000.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>44.077</td>\n",
       "      <td>1311.956766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1962</td>\n",
       "      <td>3421000.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>46.023</td>\n",
       "      <td>1452.725766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1967</td>\n",
       "      <td>3900000.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>47.768</td>\n",
       "      <td>1777.077318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1972</td>\n",
       "      <td>4506497.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>50.107</td>\n",
       "      <td>1773.498265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1977</td>\n",
       "      <td>5216550.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>51.386</td>\n",
       "      <td>1588.688299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1982</td>\n",
       "      <td>6100407.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>51.821</td>\n",
       "      <td>1408.678565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1987</td>\n",
       "      <td>7272406.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>50.821</td>\n",
       "      <td>1213.315116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1992</td>\n",
       "      <td>8381163.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>46.100</td>\n",
       "      <td>1210.884633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1997</td>\n",
       "      <td>9417789.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>40.238</td>\n",
       "      <td>1071.353818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2002</td>\n",
       "      <td>10595811.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>39.193</td>\n",
       "      <td>1071.613938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2007</td>\n",
       "      <td>11746035.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>42.384</td>\n",
       "      <td>1271.211593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1952</td>\n",
       "      <td>3080907.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>48.451</td>\n",
       "      <td>406.884115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1957</td>\n",
       "      <td>3646340.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>50.469</td>\n",
       "      <td>518.764268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1962</td>\n",
       "      <td>4277736.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>52.358</td>\n",
       "      <td>527.272182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1967</td>\n",
       "      <td>4995432.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>53.995</td>\n",
       "      <td>569.795071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1972</td>\n",
       "      <td>5861135.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>55.635</td>\n",
       "      <td>799.362176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1977</td>\n",
       "      <td>6642107.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>57.674</td>\n",
       "      <td>685.587682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1982</td>\n",
       "      <td>7636524.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>60.363</td>\n",
       "      <td>788.855041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1987</td>\n",
       "      <td>9216418.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>62.351</td>\n",
       "      <td>706.157306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1992</td>\n",
       "      <td>10704340.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>60.377</td>\n",
       "      <td>693.420786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1997</td>\n",
       "      <td>11404948.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>46.809</td>\n",
       "      <td>792.449960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2002</td>\n",
       "      <td>11926563.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>39.989</td>\n",
       "      <td>672.038623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2007</td>\n",
       "      <td>12311143.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>43.487</td>\n",
       "      <td>469.709298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1704 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  year         pop continent  lifeExp    gdpPercap\n",
       "0     Afghanistan  1997  22227415.0      Asia   41.763   635.341351\n",
       "1     Afghanistan  2002  25268405.0      Asia   42.129   726.734055\n",
       "2     Afghanistan  2007  31889923.0      Asia   43.828   974.580338\n",
       "3     Afghanistan  1952   8425333.0      Asia   28.801   779.445314\n",
       "4     Afghanistan  1957   9240934.0      Asia   30.332   820.853030\n",
       "5     Afghanistan  1962  10267083.0      Asia   31.997   853.100710\n",
       "6     Afghanistan  1967  11537966.0      Asia   34.020   836.197138\n",
       "7     Afghanistan  1972  13079460.0      Asia   36.088   739.981106\n",
       "8     Afghanistan  1977  14880372.0      Asia   38.438   786.113360\n",
       "9     Afghanistan  1982  12881816.0      Asia   39.854   978.011439\n",
       "10    Afghanistan  1987  13867957.0      Asia   40.822   852.395945\n",
       "11    Afghanistan  1992  16317921.0      Asia   41.674   649.341395\n",
       "12        Albania  1952   1282697.0    Europe   55.230  1601.056136\n",
       "13        Albania  1957   1476505.0    Europe   59.280  1942.284244\n",
       "14        Albania  1962   1728137.0    Europe   64.820  2312.888958\n",
       "15        Albania  1967   1984060.0    Europe   66.220  2760.196931\n",
       "16        Albania  1972   2263554.0    Europe   67.690  3313.422188\n",
       "17        Albania  1977   2509048.0    Europe   68.930  3533.003910\n",
       "18        Albania  1982   2780097.0    Europe   70.420  3630.880722\n",
       "19        Albania  1987   3075321.0    Europe   72.000  3738.932735\n",
       "20        Albania  1992   3326498.0    Europe   71.581  2497.437901\n",
       "21        Albania  1997   3428038.0    Europe   72.950  3193.054604\n",
       "22        Albania  2002   3508512.0    Europe   75.651  4604.211737\n",
       "23        Albania  2007   3600523.0    Europe   76.423  5937.029526\n",
       "24        Algeria  1962  11000948.0    Africa   48.303  2550.816880\n",
       "25        Algeria  1967  12760499.0    Africa   51.407  3246.991771\n",
       "26        Algeria  1972  14760787.0    Africa   54.518  4182.663766\n",
       "27        Algeria  1977  17152804.0    Africa   58.014  4910.416756\n",
       "28        Algeria  1982  20033753.0    Africa   61.368  5745.160213\n",
       "29        Algeria  1952   9279525.0    Africa   43.077  2449.008185\n",
       "...           ...   ...         ...       ...      ...          ...\n",
       "1674  Yemen, Rep.  1982   9657618.0      Asia   49.113  1977.557010\n",
       "1675  Yemen, Rep.  1987  11219340.0      Asia   52.922  1971.741538\n",
       "1676  Yemen, Rep.  1992  13367997.0      Asia   55.599  1879.496673\n",
       "1677  Yemen, Rep.  1997  15826497.0      Asia   58.020  2117.484526\n",
       "1678  Yemen, Rep.  2002  18701257.0      Asia   60.308  2234.820827\n",
       "1679  Yemen, Rep.  2007  22211743.0      Asia   62.698  2280.769906\n",
       "1680       Zambia  1952   2672000.0    Africa   42.038  1147.388831\n",
       "1681       Zambia  1957   3016000.0    Africa   44.077  1311.956766\n",
       "1682       Zambia  1962   3421000.0    Africa   46.023  1452.725766\n",
       "1683       Zambia  1967   3900000.0    Africa   47.768  1777.077318\n",
       "1684       Zambia  1972   4506497.0    Africa   50.107  1773.498265\n",
       "1685       Zambia  1977   5216550.0    Africa   51.386  1588.688299\n",
       "1686       Zambia  1982   6100407.0    Africa   51.821  1408.678565\n",
       "1687       Zambia  1987   7272406.0    Africa   50.821  1213.315116\n",
       "1688       Zambia  1992   8381163.0    Africa   46.100  1210.884633\n",
       "1689       Zambia  1997   9417789.0    Africa   40.238  1071.353818\n",
       "1690       Zambia  2002  10595811.0    Africa   39.193  1071.613938\n",
       "1691       Zambia  2007  11746035.0    Africa   42.384  1271.211593\n",
       "1692     Zimbabwe  1952   3080907.0    Africa   48.451   406.884115\n",
       "1693     Zimbabwe  1957   3646340.0    Africa   50.469   518.764268\n",
       "1694     Zimbabwe  1962   4277736.0    Africa   52.358   527.272182\n",
       "1695     Zimbabwe  1967   4995432.0    Africa   53.995   569.795071\n",
       "1696     Zimbabwe  1972   5861135.0    Africa   55.635   799.362176\n",
       "1697     Zimbabwe  1977   6642107.0    Africa   57.674   685.587682\n",
       "1698     Zimbabwe  1982   7636524.0    Africa   60.363   788.855041\n",
       "1699     Zimbabwe  1987   9216418.0    Africa   62.351   706.157306\n",
       "1700     Zimbabwe  1992  10704340.0    Africa   60.377   693.420786\n",
       "1701     Zimbabwe  1997  11404948.0    Africa   46.809   792.449960\n",
       "1702     Zimbabwe  2002  11926563.0    Africa   39.989   672.038623\n",
       "1703     Zimbabwe  2007  12311143.0    Africa   43.487   469.709298\n",
       "\n",
       "[1704 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we load a csv file with Pandas, it get's loaded into a DataFrame.\n",
    "\n",
    "DataFrame is the way Pandas represents a table, and Series is the data-structure Pandas use to represent a column. So, a data frame and series are synonomous with table and column.\n",
    "\n",
    "\n",
    "*   The columns in a data frame are the observed variables, and the rows are the observations.\n",
    "*   Pandas uses backslash `\\` to show wrapped lines when output is too wide to fit the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## EtherPad\n",
    "\n",
    "Hypothetically, the data a project you are working on is stored in a file called `microbes.csv`, which is located in a folder called `field_data`. You are doing analysis in a notebook called `analysis.ipynb`in a sibling folder called `thesis`. You're directory structure looks like this:\n",
    "    ~~~\n",
    "    your_home_directory\n",
    "    +-- field_data/\n",
    "    |   +-- microbes.csv\n",
    "    +-- thesis/\n",
    "        +-- analysis.ipynb\n",
    "    ~~~\n",
    "\n",
    "What value(s) should you pass to `read_csv` to read `microbes.csv` in `analysis.ipynb`? Vote for your answer in EtherPad.\n",
    "\n",
    "    a. \"/field_data/microbes.csv\"\n",
    "    b. \"./field_data/microbes.csv\"\n",
    "    c. \"field_data/microbes.csv\"\n",
    "    d. \"../field_data/microbes.csv\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `DataFrame.info` to find out more about a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1704 entries, 0 to 1703\n",
      "Data columns (total 6 columns):\n",
      "country      1704 non-null object\n",
      "year         1704 non-null int64\n",
      "pop          1704 non-null float64\n",
      "continent    1704 non-null object\n",
      "lifeExp      1704 non-null float64\n",
      "gdpPercap    1704 non-null float64\n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 80.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `DataFrame.describe` to get summary statistics about data.\n",
    "\n",
    "DataFrame.describe() gets the summary statistics of only the columns that have numerical data. \n",
    "All other columns are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1704.00000</td>\n",
       "      <td>1.704000e+03</td>\n",
       "      <td>1704.000000</td>\n",
       "      <td>1704.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1979.50000</td>\n",
       "      <td>2.960121e+07</td>\n",
       "      <td>59.474439</td>\n",
       "      <td>7215.327081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.26533</td>\n",
       "      <td>1.061579e+08</td>\n",
       "      <td>12.917107</td>\n",
       "      <td>9857.454543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1952.00000</td>\n",
       "      <td>6.001100e+04</td>\n",
       "      <td>23.599000</td>\n",
       "      <td>241.165877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1965.75000</td>\n",
       "      <td>2.793664e+06</td>\n",
       "      <td>48.198000</td>\n",
       "      <td>1202.060309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1979.50000</td>\n",
       "      <td>7.023596e+06</td>\n",
       "      <td>60.712500</td>\n",
       "      <td>3531.846989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1993.25000</td>\n",
       "      <td>1.958522e+07</td>\n",
       "      <td>70.845500</td>\n",
       "      <td>9325.462346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2007.00000</td>\n",
       "      <td>1.318683e+09</td>\n",
       "      <td>82.603000</td>\n",
       "      <td>113523.132900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             year           pop      lifeExp      gdpPercap\n",
       "count  1704.00000  1.704000e+03  1704.000000    1704.000000\n",
       "mean   1979.50000  2.960121e+07    59.474439    7215.327081\n",
       "std      17.26533  1.061579e+08    12.917107    9857.454543\n",
       "min    1952.00000  6.001100e+04    23.599000     241.165877\n",
       "25%    1965.75000  2.793664e+06    48.198000    1202.060309\n",
       "50%    1979.50000  7.023596e+06    60.712500    3531.846989\n",
       "75%    1993.25000  1.958522e+07    70.845500    9325.462346\n",
       "max    2007.00000  1.318683e+09    82.603000  113523.132900"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## EtherPad:\n",
    "1. Use the python cell below to find the minimum GDP per capita of all countries in 1972?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vote for your answer on EtherPad\n",
    "\n",
    "    a. 331.0\n",
    "    b. 372.0\n",
    "    c. 415.0\n",
    "    d. 424.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `DataFrame.columns` variable stores information about the data frame's columns.\n",
    "\n",
    "*   Note that this is a method, *not* a function.\n",
    "    *   Like `math.pi`.\n",
    "    *   So do not use `()` to try to call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'year', 'pop', 'continent', 'lifeExp', 'gdpPercap']\n",
      "        country  year         pop continent  lifeExp    gdpPercap\n",
      "0   Afghanistan  1997  22227415.0      Asia   41.763   635.341351\n",
      "1   Afghanistan  2002  25268405.0      Asia   42.129   726.734055\n",
      "2   Afghanistan  2007  31889923.0      Asia   43.828   974.580338\n",
      "3   Afghanistan  1952   8425333.0      Asia   28.801   779.445314\n",
      "4   Afghanistan  1957   9240934.0      Asia   30.332   820.853030\n",
      "5   Afghanistan  1962  10267083.0      Asia   31.997   853.100710\n",
      "6   Afghanistan  1967  11537966.0      Asia   34.020   836.197138\n",
      "7   Afghanistan  1972  13079460.0      Asia   36.088   739.981106\n",
      "8   Afghanistan  1977  14880372.0      Asia   38.438   786.113360\n",
      "9   Afghanistan  1982  12881816.0      Asia   39.854   978.011439\n",
      "10  Afghanistan  1987  13867957.0      Asia   40.822   852.395945\n",
      "11  Afghanistan  1992  16317921.0      Asia   41.674   649.341395\n",
      "12      Albania  1952   1282697.0    Europe   55.230  1601.056136\n",
      "13      Albania  1957   1476505.0    Europe   59.280  1942.284244\n",
      "14      Albania  1962   1728137.0    Europe   64.820  2312.888958\n",
      "15      Albania  1967   1984060.0    Europe   66.220  2760.196931\n",
      "16      Albania  1972   2263554.0    Europe   67.690  3313.422188\n",
      "17      Albania  1977   2509048.0    Europe   68.930  3533.003910\n",
      "18      Albania  1982   2780097.0    Europe   70.420  3630.880722\n",
      "19      Albania  1987   3075321.0    Europe   72.000  3738.932735\n",
      "       country  year         pop continent  lifeExp    gdpPercap\n",
      "1684    Zambia  1972   4506497.0    Africa   50.107  1773.498265\n",
      "1685    Zambia  1977   5216550.0    Africa   51.386  1588.688299\n",
      "1686    Zambia  1982   6100407.0    Africa   51.821  1408.678565\n",
      "1687    Zambia  1987   7272406.0    Africa   50.821  1213.315116\n",
      "1688    Zambia  1992   8381163.0    Africa   46.100  1210.884633\n",
      "1689    Zambia  1997   9417789.0    Africa   40.238  1071.353818\n",
      "1690    Zambia  2002  10595811.0    Africa   39.193  1071.613938\n",
      "1691    Zambia  2007  11746035.0    Africa   42.384  1271.211593\n",
      "1692  Zimbabwe  1952   3080907.0    Africa   48.451   406.884115\n",
      "1693  Zimbabwe  1957   3646340.0    Africa   50.469   518.764268\n",
      "1694  Zimbabwe  1962   4277736.0    Africa   52.358   527.272182\n",
      "1695  Zimbabwe  1967   4995432.0    Africa   53.995   569.795071\n",
      "1696  Zimbabwe  1972   5861135.0    Africa   55.635   799.362176\n",
      "1697  Zimbabwe  1977   6642107.0    Africa   57.674   685.587682\n",
      "1698  Zimbabwe  1982   7636524.0    Africa   60.363   788.855041\n",
      "1699  Zimbabwe  1987   9216418.0    Africa   62.351   706.157306\n",
      "1700  Zimbabwe  1992  10704340.0    Africa   60.377   693.420786\n",
      "1701  Zimbabwe  1997  11404948.0    Africa   46.809   792.449960\n",
      "1702  Zimbabwe  2002  11926563.0    Africa   39.989   672.038623\n",
      "1703  Zimbabwe  2007  12311143.0    Africa   43.487   469.709298\n"
     ]
    }
   ],
   "source": [
    "# print out the data frame columns\n",
    "df.columns\n",
    "print(df.columns.tolist())\n",
    "print(df.head(20))\n",
    "print(df.tail(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `index_col` to specify that a column's values should be used as row headings.\n",
    "\n",
    "*   Row headings are numbers (0 and 1 in this case).\n",
    "*   Really want to index by country.\n",
    "*   Pass the name of the column to `read_csv` as its `index_col` parameter to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>continent</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>1997</td>\n",
       "      <td>22227415.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>41.763</td>\n",
       "      <td>635.341351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>2002</td>\n",
       "      <td>25268405.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>42.129</td>\n",
       "      <td>726.734055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>2007</td>\n",
       "      <td>31889923.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>43.828</td>\n",
       "      <td>974.580338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>1952</td>\n",
       "      <td>8425333.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>28.801</td>\n",
       "      <td>779.445314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>1957</td>\n",
       "      <td>9240934.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>30.332</td>\n",
       "      <td>820.853030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             year         pop continent  lifeExp   gdpPercap\n",
       "country                                                     \n",
       "Afghanistan  1997  22227415.0      Asia   41.763  635.341351\n",
       "Afghanistan  2002  25268405.0      Asia   42.129  726.734055\n",
       "Afghanistan  2007  31889923.0      Asia   43.828  974.580338\n",
       "Afghanistan  1952   8425333.0      Asia   28.801  779.445314\n",
       "Afghanistan  1957   9240934.0      Asia   30.332  820.853030"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-read in the gapminder data with the \"country\" column/series sa the index_col\n",
    "df = pandas.read_table(\"../data/processed_data/gapminder_data.txt\", index_col=\"country\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is a `DataFrame`\n",
    "* This gives us many rows with the same index value (\"e.g. Afghanistan\")\n",
    "  * Not good practice\n",
    "* lets re-read the table without the index_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>continent</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1997</td>\n",
       "      <td>22227415.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>41.763</td>\n",
       "      <td>635.341351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2002</td>\n",
       "      <td>25268405.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>42.129</td>\n",
       "      <td>726.734055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year         pop continent  lifeExp   gdpPercap\n",
       "0  Afghanistan  1997  22227415.0      Asia   41.763  635.341351\n",
       "1  Afghanistan  2002  25268405.0      Asia   42.129  726.734055"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "df = pandas.read_table(\"../data/processed_data/gapminder_data.txt\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to csv file \n",
    "As well as the `read_table` function for reading data from a file, Pandas can write data frames to files with a `to_****` function.\n",
    "  * Pandas can write data frames to csv, html, excel (xlsx), json, and many more.  \n",
    "    E.g.  \n",
    "    `df.to_csv(\"./my_data.csv'`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Itzel\\Documents\\SDC_workshop_2018-02-10\\shell\\python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## EXERCISE:\n",
    "1. With the `gapminder_final.txt` file read in as a data frame, write out a copy of the data frame as a csv to a new file called `gapminder_final.csv` in the `data` directory in the `python_lessons` directory (\"./data\").\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "df.to_csv(\"../data/processed_data/gapminder_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- COMMIT YOUR WORK TO GITHUB --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Keypoints:\n",
    " * Use the Pandas library to do statistics on tabular data.\n",
    " * Use `index_col` to specify that a column's values should be used as row headings.\n",
    " * Use `DataFrame.info` to find out more about a data frame.\n",
    " * The `DataFrame.columns` variable stores information about the data frame's columns.\n",
    " * Use `DataFrame.T` to transpose a data frame.\n",
    " * Use `DataFrame.describe` to get summary statistics about data."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
